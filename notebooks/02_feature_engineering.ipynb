{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GDELT Conflict Predictor - Feature Engineering\n",
    "\n",
    "## Notebook Overview\n",
    "\n",
    "Based on the EDA conclusions from `GDELT_EDA_Traditional.ipynb`, this notebook implements comprehensive feature engineering for conflict prediction modeling.\n",
    "\n",
    "### Key Findings from EDA:\n",
    "- **Dataset**: 92,000 events (2015-2024), 17% conflict rate\n",
    "- **Core Features**: Date, EventRootCode, GoldsteinScale are 100% complete\n",
    "- **Issues**: High missingness in actor metadata (95-99%), moderate class imbalance\n",
    "- **Strengths**: Rich temporal structure, good geographic diversity\n",
    "\n",
    "### Feature Engineering Strategy:\n",
    "1. Drop highly incomplete features (>90% missing)\n",
    "2. Create temporal aggregation features (country-day/week level)\n",
    "3. Build rolling window metrics (conflict rates over 7, 14, 30 days)\n",
    "4. Engineer escalation indicators and trends\n",
    "5. Add country-pair interaction features\n",
    "6. Create geographic clustering features\n",
    "7. Prepare final dataset for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "Pandas version: 2.3.3\n",
      "NumPy version: 2.2.6\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import timedelta, datetime\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: File not found at ../data/gdelt_sample.csv\n",
      "Please update the data_path variable with the correct path to your GDELT dataset.\n"
     ]
    }
   ],
   "source": [
    "# Load the GDELT dataset\n",
    "data_path = '../data/gdelt_sample.csv'  # Adjust path as needed\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(data_path, low_memory=False)\n",
    "    print(f\"Dataset loaded: {df.shape[0]:,} rows, {df.shape[1]} columns\")\n",
    "    print(f\"\\nMemory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {data_path}\")\n",
    "    print(\"Please update the data_path variable with the correct path to your GDELT dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDataset Info:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m80\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mdf\u001b[49m.info()\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Display basic info\n",
    "print(\"Dataset Info:\")\n",
    "print(\"=\" * 80)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert SQLDATE to datetime\n",
    "df['Date'] = pd.to_datetime(df['SQLDATE'].astype(str), format='%Y%m%d')\n",
    "print(f\"Date range: {df['Date'].min()} to {df['Date'].max()}\")\n",
    "print(f\"Total days: {(df['Date'].max() - df['Date'].min()).days}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning & Feature Selection\n",
    "\n",
    "Based on EDA, we'll:\n",
    "- Drop features with >90% missingness\n",
    "- Handle Actor1CountryCode missingness (55.4% complete)\n",
    "- Focus on event-level and temporal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate missing percentage for each column\n",
    "missing_pct = (df.isnull().sum() / len(df) * 100).sort_values(ascending=False)\n",
    "print(\"Features with >90% missingness:\")\n",
    "print(\"=\" * 80)\n",
    "high_missing = missing_pct[missing_pct > 90]\n",
    "print(high_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with >90% missing values\n",
    "cols_to_drop = missing_pct[missing_pct > 90].index.tolist()\n",
    "print(f\"Dropping {len(cols_to_drop)} columns with >90% missingness:\")\n",
    "print(cols_to_drop)\n",
    "\n",
    "df_clean = df.drop(columns=cols_to_drop)\n",
    "print(f\"\\nDataset shape after dropping: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle Actor1CountryCode missingness - fill with 'UNKNOWN'\n",
    "if 'Actor1CountryCode' in df_clean.columns:\n",
    "    before_missing = df_clean['Actor1CountryCode'].isnull().sum()\n",
    "    df_clean['Actor1CountryCode'] = df_clean['Actor1CountryCode'].fillna('UNKNOWN')\n",
    "    print(f\"Filled {before_missing:,} missing Actor1CountryCode values with 'UNKNOWN'\")\n",
    "\n",
    "if 'Actor2CountryCode' in df_clean.columns:\n",
    "    before_missing = df_clean['Actor2CountryCode'].isnull().sum()\n",
    "    df_clean['Actor2CountryCode'] = df_clean['Actor2CountryCode'].fillna('UNKNOWN')\n",
    "    print(f\"Filled {before_missing:,} missing Actor2CountryCode values with 'UNKNOWN'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target variable: IsConflict (EventRootCode in ['14', '15', '16', '17', '18', '19', '20'])\n",
    "conflict_codes = ['14', '15', '16', '17', '18', '19', '20']\n",
    "df_clean['IsConflict'] = df_clean['EventRootCode'].astype(str).isin(conflict_codes).astype(int)\n",
    "\n",
    "print(f\"\\nTarget Variable Distribution:\")\n",
    "print(\"=\" * 80)\n",
    "print(df_clean['IsConflict'].value_counts())\n",
    "print(f\"\\nConflict Rate: {df_clean['IsConflict'].mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Temporal Aggregation Features\n",
    "\n",
    "Create country-day and country-week level aggregations to capture temporal patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporal features from date\n",
    "df_clean['Year'] = df_clean['Date'].dt.year\n",
    "df_clean['Month'] = df_clean['Date'].dt.month\n",
    "df_clean['DayOfWeek'] = df_clean['Date'].dt.dayofweek  # 0=Monday, 6=Sunday\n",
    "df_clean['DayOfYear'] = df_clean['Date'].dt.dayofyear\n",
    "df_clean['WeekOfYear'] = df_clean['Date'].dt.isocalendar().week\n",
    "df_clean['Quarter'] = df_clean['Date'].dt.quarter\n",
    "df_clean['IsWeekend'] = (df_clean['DayOfWeek'] >= 5).astype(int)\n",
    "\n",
    "print(\"Temporal features created:\")\n",
    "print(df_clean[['Date', 'Year', 'Month', 'DayOfWeek', 'WeekOfYear', 'Quarter', 'IsWeekend']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Country-Day level aggregations\n",
    "print(\"Creating country-day aggregations...\")\n",
    "\n",
    "country_day_agg = df_clean.groupby(['Actor1CountryCode', 'Date']).agg({\n",
    "    'GLOBALEVENTID': 'count',  # Number of events\n",
    "    'IsConflict': ['sum', 'mean'],  # Count and rate of conflicts\n",
    "    'GoldsteinScale': ['mean', 'std', 'min', 'max'],  # Event intensity metrics\n",
    "    'NumMentions': 'sum',  # Total media attention\n",
    "    'NumSources': 'sum',  # Source diversity\n",
    "    'NumArticles': 'sum'  # Article coverage\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "country_day_agg.columns = ['_'.join(col).strip('_') for col in country_day_agg.columns.values]\n",
    "country_day_agg.rename(columns={\n",
    "    'Actor1CountryCode': 'Country',\n",
    "    'Date': 'Date',\n",
    "    'GLOBALEVENTID_count': 'EventCount_Day',\n",
    "    'IsConflict_sum': 'ConflictCount_Day',\n",
    "    'IsConflict_mean': 'ConflictRate_Day',\n",
    "    'GoldsteinScale_mean': 'AvgGoldstein_Day',\n",
    "    'GoldsteinScale_std': 'StdGoldstein_Day',\n",
    "    'GoldsteinScale_min': 'MinGoldstein_Day',\n",
    "    'GoldsteinScale_max': 'MaxGoldstein_Day',\n",
    "    'NumMentions_sum': 'TotalMentions_Day',\n",
    "    'NumSources_sum': 'TotalSources_Day',\n",
    "    'NumArticles_sum': 'TotalArticles_Day'\n",
    "}, inplace=True)\n",
    "\n",
    "print(f\"Country-day aggregations created: {country_day_agg.shape}\")\n",
    "print(country_day_agg.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Country-Week level aggregations\n",
    "print(\"Creating country-week aggregations...\")\n",
    "\n",
    "df_clean['YearWeek'] = df_clean['Date'].dt.to_period('W').apply(lambda r: r.start_time)\n",
    "\n",
    "country_week_agg = df_clean.groupby(['Actor1CountryCode', 'YearWeek']).agg({\n",
    "    'GLOBALEVENTID': 'count',\n",
    "    'IsConflict': ['sum', 'mean'],\n",
    "    'GoldsteinScale': ['mean', 'std', 'min', 'max'],\n",
    "    'NumMentions': 'sum',\n",
    "    'NumSources': 'sum',\n",
    "    'NumArticles': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "country_week_agg.columns = ['_'.join(col).strip('_') for col in country_week_agg.columns.values]\n",
    "country_week_agg.rename(columns={\n",
    "    'Actor1CountryCode': 'Country',\n",
    "    'YearWeek': 'YearWeek',\n",
    "    'GLOBALEVENTID_count': 'EventCount_Week',\n",
    "    'IsConflict_sum': 'ConflictCount_Week',\n",
    "    'IsConflict_mean': 'ConflictRate_Week',\n",
    "    'GoldsteinScale_mean': 'AvgGoldstein_Week',\n",
    "    'GoldsteinScale_std': 'StdGoldstein_Week',\n",
    "    'GoldsteinScale_min': 'MinGoldstein_Week',\n",
    "    'GoldsteinScale_max': 'MaxGoldstein_Week',\n",
    "    'NumMentions_sum': 'TotalMentions_Week',\n",
    "    'NumSources_sum': 'TotalSources_Week',\n",
    "    'NumArticles_sum': 'TotalArticles_Week'\n",
    "}, inplace=True)\n",
    "\n",
    "print(f\"Country-week aggregations created: {country_week_agg.shape}\")\n",
    "print(country_week_agg.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Rolling Window Features\n",
    "\n",
    "Create 7-day, 14-day, and 30-day rolling window metrics for conflict prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create rolling window features\n",
    "def create_rolling_features(df, group_col, date_col, windows=[7, 14, 30]):\n",
    "    \"\"\"\n",
    "    Create rolling window features for each country.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with country-day aggregations\n",
    "        group_col: Column to group by (e.g., 'Country')\n",
    "        date_col: Date column name\n",
    "        windows: List of window sizes in days\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with rolling features added\n",
    "    \"\"\"\n",
    "    df = df.sort_values([group_col, date_col]).reset_index(drop=True)\n",
    "    \n",
    "    for window in windows:\n",
    "        print(f\"Creating {window}-day rolling features...\")\n",
    "        \n",
    "        # Rolling conflict rate\n",
    "        df[f'ConflictRate_Roll{window}d'] = df.groupby(group_col)['ConflictRate_Day'].transform(\n",
    "            lambda x: x.rolling(window=window, min_periods=1).mean()\n",
    "        )\n",
    "        \n",
    "        # Rolling conflict count\n",
    "        df[f'ConflictCount_Roll{window}d'] = df.groupby(group_col)['ConflictCount_Day'].transform(\n",
    "            lambda x: x.rolling(window=window, min_periods=1).sum()\n",
    "        )\n",
    "        \n",
    "        # Rolling event count\n",
    "        df[f'EventCount_Roll{window}d'] = df.groupby(group_col)['EventCount_Day'].transform(\n",
    "            lambda x: x.rolling(window=window, min_periods=1).sum()\n",
    "        )\n",
    "        \n",
    "        # Rolling average Goldstein scale\n",
    "        df[f'AvgGoldstein_Roll{window}d'] = df.groupby(group_col)['AvgGoldstein_Day'].transform(\n",
    "            lambda x: x.rolling(window=window, min_periods=1).mean()\n",
    "        )\n",
    "        \n",
    "        # Rolling media attention\n",
    "        df[f'TotalMentions_Roll{window}d'] = df.groupby(group_col)['TotalMentions_Day'].transform(\n",
    "            lambda x: x.rolling(window=window, min_periods=1).sum()\n",
    "        )\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"Rolling window feature function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply rolling window features to country-day aggregations\n",
    "country_day_agg = create_rolling_features(\n",
    "    country_day_agg, \n",
    "    group_col='Country', \n",
    "    date_col='Date', \n",
    "    windows=[7, 14, 30]\n",
    ")\n",
    "\n",
    "print(f\"\\nRolling features added. New shape: {country_day_agg.shape}\")\n",
    "print(\"\\nSample of rolling features:\")\n",
    "print(country_day_agg[['Country', 'Date', 'ConflictRate_Roll7d', 'ConflictRate_Roll14d', 'ConflictRate_Roll30d']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Escalation Indicators & Trend Features\n",
    "\n",
    "Detect escalating tensions and conflict trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lag features (previous day values)\n",
    "print(\"Creating lag features...\")\n",
    "\n",
    "for lag in [1, 3, 7]:\n",
    "    country_day_agg[f'ConflictRate_Lag{lag}d'] = country_day_agg.groupby('Country')['ConflictRate_Day'].shift(lag)\n",
    "    country_day_agg[f'AvgGoldstein_Lag{lag}d'] = country_day_agg.groupby('Country')['AvgGoldstein_Day'].shift(lag)\n",
    "    country_day_agg[f'EventCount_Lag{lag}d'] = country_day_agg.groupby('Country')['EventCount_Day'].shift(lag)\n",
    "\n",
    "print(\"Lag features created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create change/delta features (rate of change)\n",
    "print(\"Creating change/delta features...\")\n",
    "\n",
    "# Conflict rate change (day-over-day)\n",
    "country_day_agg['ConflictRate_Change1d'] = country_day_agg.groupby('Country')['ConflictRate_Day'].diff()\n",
    "\n",
    "# Conflict rate change (week-over-week)\n",
    "country_day_agg['ConflictRate_Change7d'] = country_day_agg.groupby('Country')['ConflictRate_Day'].diff(7)\n",
    "\n",
    "# Goldstein scale change\n",
    "country_day_agg['AvgGoldstein_Change1d'] = country_day_agg.groupby('Country')['AvgGoldstein_Day'].diff()\n",
    "country_day_agg['AvgGoldstein_Change7d'] = country_day_agg.groupby('Country')['AvgGoldstein_Day'].diff(7)\n",
    "\n",
    "# Event volume change\n",
    "country_day_agg['EventCount_Change1d'] = country_day_agg.groupby('Country')['EventCount_Day'].diff()\n",
    "country_day_agg['EventCount_Change7d'] = country_day_agg.groupby('Country')['EventCount_Day'].diff(7)\n",
    "\n",
    "print(\"Change features created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create escalation indicators\n",
    "print(\"Creating escalation indicators...\")\n",
    "\n",
    "# Escalation: conflict rate increasing over 7 days\n",
    "country_day_agg['IsEscalating_7d'] = (\n",
    "    (country_day_agg['ConflictRate_Roll7d'] > country_day_agg['ConflictRate_Lag7d']) & \n",
    "    (country_day_agg['ConflictRate_Change7d'] > 0)\n",
    ").astype(int)\n",
    "\n",
    "# Sudden spike: conflict rate doubled in 1 day\n",
    "country_day_agg['SuddenSpike'] = (\n",
    "    country_day_agg['ConflictRate_Day'] >= 2 * country_day_agg['ConflictRate_Lag1d']\n",
    ").astype(int)\n",
    "\n",
    "# Tension indicator: negative Goldstein trend (worsening relations)\n",
    "country_day_agg['NegativeTrend'] = (\n",
    "    country_day_agg['AvgGoldstein_Change7d'] < -1.0\n",
    ").astype(int)\n",
    "\n",
    "# High intensity: average Goldstein below -5 (very negative events)\n",
    "country_day_agg['HighIntensity'] = (\n",
    "    country_day_agg['AvgGoldstein_Roll7d'] < -5.0\n",
    ").astype(int)\n",
    "\n",
    "print(\"Escalation indicators created.\")\n",
    "print(f\"\\nEscalation Summary:\")\n",
    "print(f\"  Escalating (7d): {country_day_agg['IsEscalating_7d'].sum():,} instances\")\n",
    "print(f\"  Sudden Spikes: {country_day_agg['SuddenSpike'].sum():,} instances\")\n",
    "print(f\"  Negative Trends: {country_day_agg['NegativeTrend'].sum():,} instances\")\n",
    "print(f\"  High Intensity: {country_day_agg['HighIntensity'].sum():,} instances\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Country-Pair Interaction Features\n",
    "\n",
    "Create features based on historical interactions between country pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create country pair identifier\n",
    "print(\"Creating country-pair interaction features...\")\n",
    "\n",
    "if 'Actor2CountryCode' in df_clean.columns:\n",
    "    # Create sorted pair (so USA-CHN = CHN-USA)\n",
    "    df_clean['CountryPair'] = df_clean.apply(\n",
    "        lambda row: '-'.join(sorted([row['Actor1CountryCode'], row['Actor2CountryCode']])),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Country-pair aggregations\n",
    "    pair_agg = df_clean.groupby(['CountryPair', 'Date']).agg({\n",
    "        'GLOBALEVENTID': 'count',\n",
    "        'IsConflict': ['sum', 'mean'],\n",
    "        'GoldsteinScale': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    pair_agg.columns = ['_'.join(col).strip('_') for col in pair_agg.columns.values]\n",
    "    pair_agg.rename(columns={\n",
    "        'CountryPair': 'CountryPair',\n",
    "        'Date': 'Date',\n",
    "        'GLOBALEVENTID_count': 'PairEventCount',\n",
    "        'IsConflict_sum': 'PairConflictCount',\n",
    "        'IsConflict_mean': 'PairConflictRate',\n",
    "        'GoldsteinScale_mean': 'PairAvgGoldstein'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Historical conflict rate (all-time average for each pair)\n",
    "    pair_history = df_clean.groupby('CountryPair').agg({\n",
    "        'IsConflict': 'mean',\n",
    "        'GoldsteinScale': 'mean',\n",
    "        'GLOBALEVENTID': 'count'\n",
    "    }).reset_index()\n",
    "    \n",
    "    pair_history.rename(columns={\n",
    "        'IsConflict': 'PairHistoricalConflictRate',\n",
    "        'GoldsteinScale': 'PairHistoricalGoldstein',\n",
    "        'GLOBALEVENTID': 'PairTotalInteractions'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    print(f\"Country-pair features created: {pair_agg.shape}\")\n",
    "    print(f\"Country-pair history: {pair_history.shape}\")\n",
    "    print(\"\\nTop 10 country pairs by interaction count:\")\n",
    "    print(pair_history.nlargest(10, 'PairTotalInteractions')[['CountryPair', 'PairTotalInteractions', 'PairHistoricalConflictRate']])\n",
    "else:\n",
    "    print(\"Actor2CountryCode not available, skipping country-pair features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Geographic Clustering Features\n",
    "\n",
    "Create regional conflict spillover features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define regional groupings (you can expand this)\n",
    "region_mapping = {\n",
    "    # North America\n",
    "    'USA': 'North_America', 'CAN': 'North_America', 'MEX': 'North_America',\n",
    "    \n",
    "    # Europe\n",
    "    'GBR': 'Europe', 'FRA': 'Europe', 'DEU': 'Europe', 'ITA': 'Europe', 'ESP': 'Europe',\n",
    "    'POL': 'Europe', 'UKR': 'Europe', 'RUS': 'Europe',\n",
    "    \n",
    "    # Middle East\n",
    "    'ISR': 'Middle_East', 'SAU': 'Middle_East', 'IRN': 'Middle_East', 'IRQ': 'Middle_East',\n",
    "    'SYR': 'Middle_East', 'JOR': 'Middle_East', 'TUR': 'Middle_East', 'EGY': 'Middle_East',\n",
    "    \n",
    "    # Asia\n",
    "    'CHN': 'Asia', 'JPN': 'Asia', 'IND': 'Asia', 'PAK': 'Asia', 'KOR': 'Asia',\n",
    "    'PRK': 'Asia', 'AFG': 'Asia', 'BGD': 'Asia', 'IDN': 'Asia',\n",
    "    \n",
    "    # Africa\n",
    "    'NGA': 'Africa', 'ZAF': 'Africa', 'EGY': 'Africa', 'KEN': 'Africa', 'ETH': 'Africa',\n",
    "    'GHA': 'Africa', 'UGA': 'Africa', 'SOM': 'Africa',\n",
    "    \n",
    "    # South America\n",
    "    'BRA': 'South_America', 'ARG': 'South_America', 'COL': 'South_America', \n",
    "    'VEN': 'South_America', 'CHL': 'South_America',\n",
    "    \n",
    "    # Oceania\n",
    "    'AUS': 'Oceania', 'NZL': 'Oceania'\n",
    "}\n",
    "\n",
    "# Add region to country-day aggregations\n",
    "country_day_agg['Region'] = country_day_agg['Country'].map(region_mapping).fillna('Other')\n",
    "\n",
    "print(\"Region mapping applied.\")\n",
    "print(f\"\\nRegion distribution:\")\n",
    "print(country_day_agg['Region'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regional conflict spillover: average conflict rate in region\n",
    "print(\"Creating regional spillover features...\")\n",
    "\n",
    "regional_agg = country_day_agg.groupby(['Region', 'Date']).agg({\n",
    "    'ConflictRate_Day': 'mean',\n",
    "    'ConflictCount_Day': 'sum',\n",
    "    'EventCount_Day': 'sum',\n",
    "    'AvgGoldstein_Day': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "regional_agg.rename(columns={\n",
    "    'ConflictRate_Day': 'RegionalConflictRate',\n",
    "    'ConflictCount_Day': 'RegionalConflictCount',\n",
    "    'EventCount_Day': 'RegionalEventCount',\n",
    "    'AvgGoldstein_Day': 'RegionalAvgGoldstein'\n",
    "}, inplace=True)\n",
    "\n",
    "# Merge regional features back to country-day data\n",
    "country_day_agg = country_day_agg.merge(regional_agg, on=['Region', 'Date'], how='left')\n",
    "\n",
    "print(f\"Regional spillover features created. Shape: {country_day_agg.shape}\")\n",
    "print(\"\\nSample regional features:\")\n",
    "print(country_day_agg[['Country', 'Date', 'Region', 'RegionalConflictRate', 'ConflictRate_Day']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Merge Features Back to Original Dataset\n",
    "\n",
    "Join all engineered features back to the event-level dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge country-day features to original dataset\n",
    "print(\"Merging engineered features to original dataset...\")\n",
    "\n",
    "df_features = df_clean.merge(\n",
    "    country_day_agg,\n",
    "    left_on=['Actor1CountryCode', 'Date'],\n",
    "    right_on=['Country', 'Date'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"Features merged. New shape: {df_features.shape}\")\n",
    "\n",
    "# Drop duplicate country column\n",
    "if 'Country' in df_features.columns:\n",
    "    df_features.drop(columns=['Country'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If country-pair features exist, merge them\n",
    "if 'CountryPair' in df_clean.columns:\n",
    "    df_features = df_features.merge(\n",
    "        pair_history,\n",
    "        on='CountryPair',\n",
    "        how='left'\n",
    "    )\n",
    "    print(f\"Country-pair features merged. New shape: {df_features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Summary & Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all engineered features\n",
    "print(\"Engineered Features Summary:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Categorize features\n",
    "temporal_features = [col for col in df_features.columns if any(x in col for x in ['Year', 'Month', 'Day', 'Week', 'Quarter', 'Weekend'])]\n",
    "rolling_features = [col for col in df_features.columns if 'Roll' in col]\n",
    "lag_features = [col for col in df_features.columns if 'Lag' in col]\n",
    "change_features = [col for col in df_features.columns if 'Change' in col]\n",
    "escalation_features = [col for col in df_features.columns if any(x in col for x in ['Escalating', 'Spike', 'Trend', 'Intensity'])]\n",
    "pair_features = [col for col in df_features.columns if 'Pair' in col]\n",
    "regional_features = [col for col in df_features.columns if 'Regional' in col or col == 'Region']\n",
    "\n",
    "print(f\"\\nTemporal features ({len(temporal_features)}): {temporal_features}\")\n",
    "print(f\"\\nRolling window features ({len(rolling_features)}): {rolling_features}\")\n",
    "print(f\"\\nLag features ({len(lag_features)}): {lag_features}\")\n",
    "print(f\"\\nChange/delta features ({len(change_features)}): {change_features}\")\n",
    "print(f\"\\nEscalation indicators ({len(escalation_features)}): {escalation_features}\")\n",
    "print(f\"\\nCountry-pair features ({len(pair_features)}): {pair_features}\")\n",
    "print(f\"\\nRegional features ({len(regional_features)}): {regional_features}\")\n",
    "\n",
    "total_engineered = len(temporal_features) + len(rolling_features) + len(lag_features) + len(change_features) + len(escalation_features) + len(pair_features) + len(regional_features)\n",
    "print(f\"\\nTotal engineered features: {total_engineered}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for remaining missing values\n",
    "print(\"\\nMissing values in engineered features:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "all_engineered_features = temporal_features + rolling_features + lag_features + change_features + escalation_features + pair_features + regional_features\n",
    "missing_in_features = df_features[all_engineered_features].isnull().sum().sort_values(ascending=False)\n",
    "missing_in_features = missing_in_features[missing_in_features > 0]\n",
    "\n",
    "if len(missing_in_features) > 0:\n",
    "    print(missing_in_features)\n",
    "    print(f\"\\nNote: Lag and change features may have NaN for first few days (expected).\")\n",
    "else:\n",
    "    print(\"No missing values in engineered features!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Processed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the feature-engineered dataset\n",
    "output_path = '../data/gdelt_features.csv'\n",
    "\n",
    "print(f\"Saving processed dataset to {output_path}...\")\n",
    "df_features.to_csv(output_path, index=False)\n",
    "print(f\"Dataset saved successfully!\")\n",
    "print(f\"Final shape: {df_features.shape}\")\n",
    "print(f\"File size: {df_features.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also save aggregated country-day dataset (for time series modeling)\n",
    "country_day_output = '../data/gdelt_country_day_features.csv'\n",
    "\n",
    "print(f\"\\nSaving country-day aggregated dataset to {country_day_output}...\")\n",
    "country_day_agg.to_csv(country_day_output, index=False)\n",
    "print(f\"Country-day dataset saved successfully!\")\n",
    "print(f\"Shape: {country_day_agg.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Final Summary & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FEATURE ENGINEERING COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nOriginal dataset: {df.shape}\")\n",
    "print(f\"After cleaning: {df_clean.shape}\")\n",
    "print(f\"With engineered features: {df_features.shape}\")\n",
    "print(f\"Features added: {df_features.shape[1] - df_clean.shape[1]}\")\n",
    "\n",
    "print(f\"\\nTarget variable (IsConflict):\")\n",
    "print(f\"  Conflict events: {df_features['IsConflict'].sum():,} ({df_features['IsConflict'].mean()*100:.2f}%)\")\n",
    "print(f\"  Non-conflict events: {(df_features['IsConflict'] == 0).sum():,} ({(1-df_features['IsConflict'].mean())*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nOutputs saved:\")\n",
    "print(f\"  1. Event-level features: {output_path}\")\n",
    "print(f\"  2. Country-day features: {country_day_output}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 80)\n",
    "print(\"NEXT STEPS:\")\n",
    "print(\"=\" * 80)\n",
    "print(\"1. Load gdelt_features.csv in the baseline modeling notebook\")\n",
    "print(\"2. Implement time series cross-validation (train on past, test on future)\")\n",
    "print(\"3. Build baseline models: Logistic Regression, Random Forest, XGBoost\")\n",
    "print(\"4. Handle class imbalance with SMOTE or class weights\")\n",
    "print(\"5. Evaluate with Precision, Recall, F1, ROC-AUC, PR-AUC\")\n",
    "print(\"6. Analyze feature importance and iterate on features\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
